# -*- coding: utf-8 -*-
"""Copy of HW3_Anuradha_Kandappan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EAaVKlBbC9WEkIFJ2DEmWVlYQuXNdoEg

# **Import necessay package and load data**
"""

import pandas as pd
import nltk
nltk.download('vader_lexicon')
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import csv
import nltk
nltk.download('stopwords')
nltk.download('punkt')


# load the NPS Survey Comments file
SurveyDf = pd.read_csv("NPS_Comments.csv")
# check to confirm if data loaded successfully
SurveyDf.head()

# start investigating the data by NPS category - Promoter, Passive, Detractor
print(len(SurveyDf[SurveyDf['nps']=='Promoter']))
print()
print(len(SurveyDf[SurveyDf['nps']=='Passive']))
print()
print(len(SurveyDf[SurveyDf['nps']=='Detractor']))
print()

#Quartile Analysis on wordcount
SurveyDf['WordCount'] = SurveyDf['comment'].str.count("\S\s+\S")+1
SurveyDf['WordCount'].describe()

#compute mean word counts
print(SurveyDf['comment'][0])
print(SurveyDf['WordCount'][0])
print(SurveyDf[SurveyDf['nps']=='Promoter']['WordCount'].mean())
print(SurveyDf[SurveyDf['nps']=='Passive']['WordCount'].mean())
print(SurveyDf[SurveyDf['nps']=='Detractor']['WordCount'].mean())

print(len(SurveyDf[SurveyDf['nps']=='Promoter']))
print(len(SurveyDf[SurveyDf['nps']=='Passive']))
print(len(SurveyDf[SurveyDf['nps']=='Detractor']))

#boxplot visualization of wordcount by NPS category 
sns.boxplot(data=SurveyDf, x='nps', y='WordCount')

"""# **Perform Sentiment Analysis**"""

from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.sentiment import SentimentAnalyzer
sid = SentimentIntensityAnalyzer()
sentimentScoreAry = []
sentimentAry = []


for t in SurveyDf['comment']:
    ss = sid.polarity_scores(t)['compound']
    sentimentScoreAry.append(ss)
    if (ss > 0):
        sentimentAry.append('pos')
    elif (ss < 0):
        sentimentAry.append('neg')
    else:
        sentimentAry.append('neu')

sentimentScoreAry
SurveyDf['sentiment_score'] = sentimentScoreAry
SurveyDf['sentiment'] = sentimentAry


sns.countplot(data=SurveyDf, hue='sentiment', x='nps')

SurveyDf['sentiment'].describe()

sns.boxplot(data=SurveyDf, x='nps', y='sentiment_score')
sns.lmplot(data=SurveyDf, x='WordCount', y='sentiment_score', hue='nps', ci=False)

"""# Import necessary package for Tokenize, WordClound, Stopword, Stemming"""

from nltk.tokenize import TweetTokenizer
from nltk.corpus import stopwords
tt = TweetTokenizer()
import wordcloud
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
stop_words = set(stopwords.words('english'))
from nltk.stem import SnowballStemmer
stemmer = SnowballStemmer("english")

"""## **Tokentize the comments**"""

PromoterComments = SurveyDf[SurveyDf['nps'] == 'Promoter']['comment'].apply(tt.tokenize)
PassiveComments = SurveyDf[SurveyDf['nps'] == 'Passive']['comment'].apply(tt.tokenize)
DetractorComments = SurveyDf[SurveyDf['nps'] == 'Detractor']['comment'].apply(tt.tokenize)

"""# Tokenize Comments by NPS category"""

# Promoter Comment
PromoterTokenizedComments = []
PromoterStemmedTokenizedComments = []
for comment in PromoterComments:
  newT = []
  for t in comment:
    t = t.strip()
    PromoterTokenizedComments.append(t.lower())
    newT.append(stemmer.stem(t.lower()))
  PromoterStemmedTokenizedComments.append(" ".join(newT))

print(len(PromoterTokenizedComments))
print(len(PromoterStemmedTokenizedComments))

allPromoterComments = " ".join(mt for mt in PromoterTokenizedComments)
allPromoterStemmedComments = " ".join(stt for stt in PromoterStemmedTokenizedComments)

# Passive Comment
PassiveTokenizedComments = []
PassiveStemmedTokenizedComments = []
for comment in PassiveComments:
  newT = []
  for t in comment:
    t = t.strip()
    PassiveTokenizedComments.append(t.lower())
    newT.append(stemmer.stem(t.lower()))
  PassiveStemmedTokenizedComments.append(" ".join(newT))

print(len(PassiveTokenizedComments))
print(len(PassiveStemmedTokenizedComments))

allPassiveComments = " ".join(mt for mt in PassiveTokenizedComments)
allPassiveStemmedComments = " ".join(stt for stt in PassiveStemmedTokenizedComments)

# Detractor Comment
DetractorTokenizedComments = []
DetractorStemmedTokenizedComments = []
for comment in DetractorComments:
  newT = []
  for t in comment:
    t = t.strip()
    DetractorTokenizedComments.append(t.lower())
    newT.append(stemmer.stem(t.lower()))
  DetractorStemmedTokenizedComments.append(" ".join(newT))

print(len(DetractorTokenizedComments))
print(len(DetractorStemmedTokenizedComments))

allDetractorComments = " ".join(mt for mt in DetractorTokenizedComments)
allDetractorStemmedComments = " ".join(stt for stt in DetractorStemmedTokenizedComments)

"""# **Word Cloud for Promoters based on different Vectorization choices**"""

stopWords = stopwords.words('english')
stopWords.append('dell')
stopWords.append('emc')

#Tokenized Comments
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(allPromoterComments)  
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("Promoter Comments - Tokenized")
plt.axis("off")
plt.show()

#based on Stemmed Comments
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(allPromoterStemmedComments)  
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("Promoter Comments - Stemmed")
plt.axis("off")
plt.show()

#based on removing Stop words  
wordcloud = WordCloud(stopwords=stopWords, background_color="white").generate(allPromoterStemmedComments)
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("Promoter Comments - Removing Stop Words")
plt.axis("off")
plt.show()

"""# **Word Cloud for Passive based on different Vectorization choices**"""

#Tokenized Comments
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(allPassiveComments)  
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("Passive Comments - Tokenized")
plt.axis("off")
plt.show()

#based on Stemmed Comments
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(allPassiveStemmedComments)  
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("Passive Comments - Stemmed")
plt.axis("off")
plt.show()

#based on removing Stop words  
wordcloud = WordCloud(stopwords=stopWords, background_color="white").generate(allPassiveStemmedComments)
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("Passive Comments - Removing Stop Words")
plt.axis("off")
plt.show()

"""# **Word Cloud for Detractors based on different Vectorization choices**"""

#Tokenized Comments
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(allDetractorComments)  
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("Detractor Comments - Tokenized")
plt.axis("off")
plt.show()

#based on Stemmed Comments
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(allDetractorStemmedComments)  
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("Detractor Comments - Stemmed")
plt.axis("off")
plt.show()

#based on removing Stop words  
wordcloud = WordCloud(stopwords=stopWords, background_color="white").generate(allDetractorStemmedComments)
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("Detractor Comments - Removing Stop Words")
plt.axis("off")
plt.show()